{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化指定场景视角的关键点和抓取位姿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n",
      "WARNING:root:Failed to import geometry msgs in rigid_transformations.py.\n",
      "WARNING:root:Failed to import ros dependencies in rigid_transforms.py\n",
      "WARNING:root:autolab_core not installed as catkin package, RigidTransform ros methods will be unavailable\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io as scio\n",
    "from models.graspnet import GraspNet, pred_decode\n",
    "from dataset.graspnet_dataset import GraspNetDataset, collate_fn\n",
    "from graspnetAPI import GraspGroup, GraspNetEval\n",
    "from graspnetAPI.utils.utils import generate_scene_model\n",
    "from graspnetAPI.utils.eval_utils import get_scene_name, create_table_points, parse_posevector, \\\n",
    "    load_dexnet_model, transform_points, compute_point_distance, compute_closest_points, \\\n",
    "        voxel_sample_points, topk_grasps, get_grasp_score, collision_detection, eval_grasp\n",
    "from utils.data_utils import CameraInfo, transform_point_cloud, \\\n",
    "    create_point_cloud_from_depth_image, get_workspace_mask, remove_invisible_grasp_points\n",
    "from utils.collision_detector import ModelFreeCollisionDetector\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "os.environ['DISPLAY'] = \":11.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data path and collision labels...: 100%|██████████| 90/90 [00:00<00:00, 361.87it/s]\n",
      "Loading data path...: 100%|██████████| 90/90 [00:00<00:00, 224.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DATASET = GraspNetDataset(\"data/Benchmark/graspnet\", valid_obj_idxs=None, grasp_labels=None, split=\"test\", \n",
    "                               camera=\"realsense\", num_points=20000, remove_outlier=True, \n",
    "                               augment=False, load_label=False)\n",
    "\n",
    "ge = GraspNetEval(root=\"data/Benchmark/graspnet\", camera=\"realsense\", split=\"test\")\n",
    "net = GraspNet(input_feature_dim=0, num_view=300, num_angle=12, num_depth=4, \n",
    "               cylinder_radius=0.05, hmin=-0.02, hmax_list=[0.01,0.02,0.03,0.04], is_training=False)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"logs/log_rs_spotr/2023-10-06-23-21/checkpoint.tar\")\n",
    "net.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(scene_id, img_id, raw=False):\n",
    "    ret_dict = TEST_DATASET.get_data((scene_id - 100) * 256 + img_id, return_raw_cloud=raw)\n",
    "    if raw == False:\n",
    "        pcd = ret_dict['point_clouds']\n",
    "        obj_mask = ret_dict['seg_mask']\n",
    "        pcd_obj_inds = np.argwhere(obj_mask>0).squeeze() # (N_obj,)\n",
    "        pcd_obj = pcd[obj_mask>0]\n",
    "        num_pts_obj = 1024\n",
    "        if len(pcd_obj) >= num_pts_obj:\n",
    "            idxs = np.random.choice(len(pcd_obj), num_pts_obj, replace=False)\n",
    "        else:\n",
    "            idxs1 = np.arange(len(pcd_obj))\n",
    "            idxs2 = np.random.choice(len(pcd_obj), num_pts_obj-len(pcd_obj), replace=True)\n",
    "            idxs = np.concatenate([idxs1, idxs2], axis=0)\n",
    "        pcd_obj_inds = pcd_obj_inds[idxs] # (1024, )\n",
    "        ret_dict['pcd_obj_inds'] = pcd_obj_inds\n",
    "    \n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApproachNet forward time: 0.5049705505371094 ms.\n",
      "crop time: 0.7505416870117188\n",
      "operation time: 0.7414817810058594 ms.\n",
      "tolerance time: 0.6802082061767578 ms.\n",
      "total forward time: 180.61256408691406 ms.\n",
      "collision rate: 0.69\n",
      "\n",
      "ApproachNet forward time: 0.6327629089355469 ms.\n",
      "crop time: 0.7264614105224609\n",
      "operation time: 0.7185935974121094 ms.\n",
      "tolerance time: 0.6577968597412109 ms.\n",
      "total forward time: 183.57157707214355 ms.\n",
      "collision rate: 0.67\n",
      "\n",
      "ApproachNet forward time: 0.6313323974609375 ms.\n",
      "crop time: 0.7460117340087891\n",
      "operation time: 0.7123947143554688 ms.\n",
      "tolerance time: 0.6577968597412109 ms.\n",
      "total forward time: 183.3477020263672 ms.\n",
      "collision rate: 0.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scene_id = 100\n",
    "img_id = 0\n",
    "\n",
    "for scene_id in range(103, 106):\n",
    "    # 点云，颜色，segmentation， 物体点索引\n",
    "    data = [get_data(scene_id, img_id)]\n",
    "\n",
    "    # 扩展 batch 维度\n",
    "    batch_data = collate_fn(data)\n",
    "\n",
    "    # 送到 GPU\n",
    "    for key in batch_data:\n",
    "        if 'list' in key:\n",
    "            for i in range(len(batch_data[key])):\n",
    "                for j in range(len(batch_data[key][i])):\n",
    "                    batch_data[key][i][j] = batch_data[key][i][j].to(device)\n",
    "        else:\n",
    "            batch_data[key] = batch_data[key].to(device)\n",
    "\n",
    "    # Forward pass，保存关键点和场景\n",
    "    with torch.no_grad():\n",
    "        end_points = net(batch_data)\n",
    "        grasp_preds = pred_decode(end_points)\n",
    "\n",
    "    # 保存关键点\n",
    "    global_p = end_points['global_p']\n",
    "\n",
    "    # 抓取位姿送到 CPU\n",
    "    preds = grasp_preds[0].detach().cpu().numpy()\n",
    "    gg = GraspGroup(preds)\n",
    "    num_pred = len(gg)\n",
    "    # total_pred += num_pred\n",
    "\n",
    "    # collision detection \n",
    "    cloud, _ = get_data(scene_id, img_id, raw=True)\n",
    "    mfcdetector = ModelFreeCollisionDetector(cloud, voxel_size=0.01)\n",
    "    collision_mask = mfcdetector.detect(gg, approach_dist=0.05, collision_thresh=0.01)\n",
    "    num_coll = np.count_nonzero(collision_mask)\n",
    "    # total_coll += num_coll\n",
    "    print(f\"collision rate: {(num_coll/num_pred):.2f}\\n\")\n",
    "    gg = gg[~collision_mask]\n",
    "\n",
    "    # 可视化抓取\n",
    "    # table = create_table_points(1.0, 1.0, 0.05, dx=-0.5, dy=-0.5, dz=-0.05, grid_size=0.008)\n",
    "    # _, pose_list, camera_pose, align_mat = ge.get_model_poses(scene_id, img_id)\n",
    "    # table_trans = transform_points(table, np.linalg.inv(np.matmul(align_mat, camera_pose)))\n",
    "    # t = o3d.geometry.PointCloud()\n",
    "    # t.points = o3d.utility.Vector3dVector(table_trans)\n",
    "    # model_list = generate_scene_model(\"data/Benchmark/graspnet\", 'scene_%04d' % scene_id , \n",
    "    #                                 img_id, return_poses=False, align=False, camera=\"realsense\")\n",
    "\n",
    "    nms_gg = gg.nms()\n",
    "    nms_gg = nms_gg[:10]\n",
    "    grasps_geometry = nms_gg.to_open3d_geometry_list()\n",
    "    pcd = ge.loadScenePointCloud(scene_id, \"realsense\", img_id)\n",
    "    o3d.visualization.draw_geometries([pcd, *grasps_geometry])\n",
    "    # o3d.visualization.draw_geometries([pcd, *grasps_geometry, *model_list])\n",
    "    # o3d.visualization.draw_geometries([*grasps_geometry, *model_list, t])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log 抓取分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log 0.1 = 2.3026\n",
      "log 0.2 = 1.6094\n",
      "log 0.30000000000000004 = 1.2040\n",
      "log 0.4 = 0.9163\n",
      "log 0.5 = 0.6931\n",
      "log 0.6 = 0.5108\n",
      "log 0.7000000000000001 = 0.3567\n",
      "log 0.8 = 0.2231\n",
      "log 0.9 = 0.1054\n",
      "log 1.0 = 0.0000\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "    print(f\"log {i} = {np.log(1/i):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 传播 top-k 交叉熵 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4968)\n"
     ]
    }
   ],
   "source": [
    "# 假设你有一个模型的预测值 predictions 和对应的目标真值 targets\n",
    "predictions = torch.randn((2, 2, 1024))  # 模型的预测值\n",
    "targets = torch.randint(0, 1, (2, 1024)).long()  # 随机生成一个目标标签，这里假设有1000个类别\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# 计算误差（可以是任何形式的误差，如交叉熵、均方误差等）\n",
    "errors = criterion(predictions, targets)\n",
    "\n",
    "# 使用torch.topk获取前512个最大误差项的索引\n",
    "topk_values, topk_indices = torch.topk(errors, k=512)\n",
    "\n",
    "# 仅保留前512个最大误差项的损失\n",
    "loss = torch.mean(topk_values)\n",
    "\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onebillion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
